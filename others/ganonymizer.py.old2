import numpy as np
import argparse
import cv2
import time
import torch
from torch.utils.serialization import load_lua

from inpaint.glcic.inpaint import gl_inpaint
from inpaint.glcic.pre_support import *
from inpaint.glcic.utils import *
from inpaint.glcic.completionnet_places2 import completionnet_places2
from detection.ssd.ssd512 import detect


def main():
    args = get_parser()

    # set a device
    device = set_device(args)

    # set networks
    detect_model, inpaint_model, datamean = set_networks(args, device)

    # GANonymizer
    gano = GANonymizer(args, device, detect_model, inpaint_model, datamean)

    if args.video != None:
        apply_to_video(args, gano)
    elif args.image != None:
        apply_to_image(args, gano)
    else:
        print('[ERROR] Select an input source.')


def get_parser():
    parser = argparse.ArgumentParser()
# parser.add_argument('--image', default='./images/example_12.jpg')
    parser.add_argument('--save_cap_dir', default=None)
    parser.add_argument('--video', type=str)
    parser.add_argument('--image', type=str)
    parser.add_argument('--prototxt', default='./detection/ssd/cfgs/deploy.prototxt', help='path to Caffe deploy prototxt file')
    parser.add_argument('--model', default='./detection/ssd/weights/VGG_VOC0712Plus_SSD_512x512_iter_240000.caffemodel', help='path to Caffe pre-trained file')
    parser.add_argument('--inp_param', default='./inpaint/glcic/completionnet_places2.pth')
    parser.add_argument('--output', default='')
    parser.add_argument('--cuda', default=None)
    parser.add_argument('--conf', type=float, default=0.15, help='minimum probability to filter weak detections')
    parser.add_argument('--fps', type=float, default=10.0)
    parser.add_argument('--show', action='store_true')
    parser.add_argument('--postproc', action='store_true')

    args = parser.parse_args()

    return args


def set_networks(args, device):
    print('[INFO] loading model...')
    detect_model = cv2.dnn.readNetFromCaffe(args.prototxt, args.model)

    model = completionnet_places2
    param = torch.load(args.inp_param)
    model.load_state_dict(param)
    model.eval()
    model.to(device)
    datamean = torch.tensor([0.4560, 0.4472, 0.4155], device=device)

    return detect_model, model, datamean


def set_device(args):
    if args.cuda != None:
        device = torch.device('cuda:{}'.format(args.cuda) if torch.cuda.is_available() else 'cpu')
    else:
        device = 'cpu'
    print('[INFO] device is {}'.format(device))
    
    return device


def load_video(args):
    print('[INFO] loading video...')
    cap = cv2.VideoCapture(args.video)
    W = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    H = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    fps = cap.get(cv2.CAP_PROP_FPS)
    print('[INFO] total frame: {}, fps: {}, width: {}, height: {}'.format(frames, fps, W, H))

    return cap, fps, frames
    

# def apply_to_image(args, gano):
#     # whole, ssd, glcic, reconst
#     elapsed = [0, 0, 0, 0]
#     input = cv2.imread(args.input)
# 
#     # process
#     elapsed, output = process_image(input, elapsed, gano)
# 
#     save_path = './data/images/' + args.input.split('/')[-1]
#     cv2.imwrite(save_path, output)
# 
# 
# def apply_to_video(args, gano):
#     # set variables
#     video = np.array([])
#     count = 1
#     # whole, ssd, glcic, reconst
#     elapsed = [0, 0, 0, 0]
#     total_time = [0, 0, 0, 0]
# 
#     # video data
#     cap, origin_fps, frames = load_video(args)
# 
#     while(cap.isOpened()):
#         print('')
#         begin_process = time.time()
#         ret, frame = cap.read()
#         if ret:
#             print('[INFO] count frame: {}/{}'.format(count, frames))
# 
#             # process
#             elapsed, output = process_image(frame, elapsed, gano)
# 
#             # append frame to video
#             video = append_frame(args, frame, output, video, count)
# 
#             # print the process info per iteration
#             total_time, count = print_info_per_process(args, begin_process, elapsed, count, total_time)
#             
#     ### Stop video process
#     cap.release()
#     cv2.destroyAllWindows()
# 
#     ### Save video
#     save_video(args, video)
# 
# 
# def process_image(input, elapsed, gano):
#     obj_rec = []
# 
#     # detect
#     obj_rec, elapsed[1] = gano.detect(input, obj_rec)
# 
#     # create mask
#     mask = np.zeros((input.shape[0], input.shape[1], 3))
#     mask = gano.create_mask(input, mask, obj_rec)
# 
#     # reconstruct
#     output, elapsed[2], elapsed[3] = gano.reconstruct(input, mask, obj_rec)
#     
#     return elapsed, output
# 
# 
# def append_frame(args, input, output, video, count):
#     ### Append the output frame to the Entire video list
#     concat = cv2.vconcat([input, output])
#     concat = concat[np.newaxis, :, :, :]
#     # print('[CHECK] concat.shape: {}'.format(concat.shape))
#     if count == 1:
#         video = concat.copy()
#     else:
#         video = np.concatenate((video, concat), axis=0)
#     if args.save_cap_dir != None:
#         cv2.imwrite('{}out_{}.png'.format(args.save_cap_dir, count), output)
# 
#     return video
# 
# 
# def print_info_per_process(args, begin, elapsed, count, total):
#     ### Print the elapsed time of processing
#     elapsed[0] = time.time() - begin
#     total[0] += elapsed[0]
#     total[1] += elapsed[1]
#     total[2] += elapsed[2]
#     total[3] += elapsed[3]
# 
#     print('[TIME] Whole process time: {}'.format(elapsed[0]))
# 
#     if count % 10 == 0:
#         print('')
#         print('[TIME] SSD average time per frame: {}'.format(total[1] / count))
#         print('[TIME] GLCIC average time per frame: {}'.format(total[2] / count))
#         print('[TIME] Reconstruction average time per frame: {}'.format(total[3] / count))
#         print('[TIME] Whole process average time per frame: {}'.format(total[0] / count))
# 
#     count += 1
# 
#     return total, count
# 
# 
# def save_video(args, video):
#     video_name = args.video.split('/')[-1]
#     outfile = './data/video/out{}_{}'.format(args.output, video_name)
#     fps = args.fps
#     codecs = 'H264'
#     # ret, frames, height, width, ch = video.shape
#     frames, height, width, ch = video.shape
# 
#     fourcc = cv2.VideoWriter_fourcc(*codecs)
#     writer = cv2.VideoWriter(outfile, fourcc, fps, (width, height))
# 
#     for i in range(frames):
#         writer.write(video[i])
#     writer.release()
# 
# 
# 
# class GANonymizer:
#     def __init__(self, args, device, detect_model, inpaint_model, datamean):
#         self.conf = args.conf
#         self.device = device
#         self.detect_model = detect_model
#         self.inpaint_model = inpaint_model
#         self.datamean = datamean
#         self.postproc = args.postproc
# 
#         self.time_ssd = 0
#         self.time_glcic = 0
#         self.time_reconstruct = 0
# 
# 
#     def detect(self, input, obj_rec):
#         ### detection privacy using SSD
#         begin_ssd = time.time()
#         obj_rec = detect(input, self.detect_model, self.conf, obj_rec)
#         elapsed_ssd = time.time() - begin_ssd
#         print('[TIME] SSD elapsed time: {}'.format(elapsed_ssd))
#         
#         return obj_rec, elapsed_ssd
# 
#     
#     def create_mask(self, input, mask, obj_rec):
#         for rec in obj_rec:
#             ul_y, ul_x, dr_y, dr_x = \
#                     rec[0], rec[1], rec[0] + rec[2], rec[1] + rec[3]
#             cut_img = input[ul_y:dr_y, ul_x:dr_x]
#             if cut_img.shape[0] > 1 and cut_img.shape[1] > 1:
#                 mask[ul_y:dr_y, ul_x:dr_x] = np.ones((cut_img.shape[0], cut_img.shape[1], 3)) * 255
#                 mask = mask.astype('uint8')
# 
#         mask = mask.astype('uint8')
#         # inpaint = cv2.inpaint(image, mask, 1, cv2.INPAINT_NS)
#         
#         return mask
# 
# 
#     def reconstruct(self, input, mask, obj_rec):
#         ### Inpainting using glcic
#         if mask.max() > 0:
#             begin_reconst = time.time()
#             print('[INFO] Removing specific objects...')
#             self.origin = input.copy().shape
# 
#             # prepadding
#             flag = {'hu':False, 'hd':False, 'vl':False, 'vr':False}
#             input, mask, flag = self.prepadding(input, mask, flag)
# 
#             # pseudo mask division
#             input, mask = self.PMD(input, mask, obj_rec)
# 
#             begin_glcic = time.time()
#             output = gl_inpaint(input, mask, self.datamean, self.inpaint_model, self.postproc, self.device)
#             elapsed_glcic = time.time() - begin_glcic
#             print('[TIME] GLCIC elapsed time: {}'.format(elapsed_glcic))
# 
#             # cut prepadding
#             output = self.cutpadding(output, flag)
# 
#             elapsed_reconst = time.time() - begin_reconst
#             print('[TIME] Reconstruction elapsed time: {}'.format(elapsed_reconst))
# 
#         else:
#             output = input
# 
#         return output, elapsed_glcic, elapsed_reconst
# 
# 
#     def prepadding(self, input, mask, flag):
#         ### prepadding
#         i, j, k = np.where(mask>=10)
#         if i.max() > self.origin[0] - 5 or j.max() > self.origin[1] - 5 or \
#                 i.min() < 4 or j.min() < 4:
#             print('[INFO] prepadding images...')
#             input, mask, flag = pre_padding(input, mask, j, i, self.origin, flag)
# 
#         return input, mask, flag
# 
# 
#     def cutpadding(self, output, flag):
#         ### cut pre_padding
#         if flag['hu'] or flag['hd'] or flag['vl'] or flag['vr']:
#             output = cut_padding(output, self.origin, flag)
# 
#         output = output * 255 # denormalization
#         output = output.astype('uint8')
# 
#         return output 
# 
# 
#     def PMD(self, input, mask, obj_rec):
#         ### pseudo mask division
#         large_thresh = 150
#         pmd_f = False
#         for r in obj_rec:
#             y, x, h, w = r
#             if y < 0 or y >= input.shape[0] or \
#                     x < 0 or x >= input.shape[1] or \
#                     h > large_thresh or w > large_thresh:
#                 # h > input.shape[0]*0.8 or w > input.shape[1]/2:
#                 obj_rec.remove(r)
# 
#             if w > large_thresh or h > large_thresh:
#                 pmd_f = True
# 
#         if pmd_f:
#             print('[INFO] pseudo mask division...')
#             input256 = cv2.resize(input, (256, 256))
#             mask256 = cv2.resize(mask, (256, 256))
#             out256 = gl_inpaint(input256, mask256, self.datamean, self.inpaint_model, self.postproc, self.device)
#             out256 = cv2.resize(out256, (input.shape[1], input.shape[0]))
#             out256 = (out256 * 255).astype('uint8')
# 
#             input, mask = pseudo_mask_division(input, out256, mask, obj_rec, [256, 256], large_thresh)
# 
#         return input, mask
# 
# 
# if __name__ == '__main__':
#     main()

if __name__ == '__main__':
    args = get_parser()

    # set variables
    video = np.array([])
    count_frame = 1
    total_time_ssd = 0
    total_time_glcic = 0
    total_time_inpaint = 0

    # set a device
    device = set_device(args)

    # video data
    cap, origin_fps = load_video(args)

    # set networks
    detect_model, inpaint_model = set_networks(args) 

    t0 = time.time()
    while(cap.isOpened()):
        print('')
        t1 = time.time()
        ret, frame = cap.read()
        if ret:
            print('[INFO] count frame: {}/{}'.format(count_frame, count))
            
            ### Begin ganonymizer

            ### detection privacy using SSD
            ts_1 = time.time()
            obj_rec = []
            mask, obj_rec = detect(frame, net, args.conf, obj_rec)
            elapsed_ssd = time.tiem() - ts_1
            total_time_ssd += elapsed_ssd
            print('[TIME] detection time per frame: {}'.format(elapsed_ssd))

            ### Inpainting using glcic
            if mask.max() > 0:
                ts_2 = time.time()
                print('[INFO] Removing specific objects...')
                origin = frame.shape
                n_input = frame.copy()
                n_mask = mask.copy()

                ### prepadding
                i, j, k = np.where(n_mask>=10)
                flag = {'hu':False, 'hd':False, 'vl':False, 'vr':False}
                if i.max() > origin[0] - 5 or j.max() > origin[1] - 5 or i.min() < 4 or j.min() < 4:
                    print('[INFO] prepadding images...')
                    n_input, n_mask, flag = pre_padding(n_input, n_mask, j, i, origin, flag)


                ### pseudo mask division
                large_thresh = 150
                pmd_f = False
                for r in obj_rec:
                    y, x, h, w = r
                    if y < 0 or y >= n_input.shape[0] or \
                            x < 0 or x >= n_input.shape[1] or \
                            h > large_thresh or w > large_thresh:
                        # h > n_input.shape[0]*0.8 or w > n_input.shape[1]/2:
                        obj_rec.remove(r)

                    if w > large_thresh or h > large_thresh:
                        pmd_f = True

                if pmd_f:
                    print('[INFO] pseudo mask division...')
                    input256 = cv2.resize(n_input, (256, 256))
                    mask256 = cv2.resize(n_mask, (256, 256))
                    out256 = gl_inpaint(input256, mask256, datamean, model, args.postproc, device)
                    out256 = cv2.resize(out256, (n_input.shape[1], n_input.shape[0]))
                    out256 = (out256 * 255).astype('uint8')
                    n_input, n_mask = pseudo_mask_division(n_input, out256, n_mask, obj_rec, [256, 256], large_thresh)

                inp_only_s = time.time()
                output = gl_inpaint(n_input, n_mask, datamean, model, args.postproc, device)
                inp_only_e = time.time()
                total_time_glcic += inp_only_e - inp_only_s

                ### cut pre_padding
                if flag['hu'] or flag['hd'] or flag['vl'] or flag['vr']:
                    output = cut_padding(output, origin, flag)

                output = output * 255 # denormalization
                output = output.astype('uint8')

                inp_e = time.time()
                print('[TIME] inpainting time per frame: {}'.format(inp_e - inp_s))
                total_time_inpaint += inp_e - inp_s
            else:
                output = frame

            ### Append the output frame to the Entire video list
            concat = cv2.vconcat([frame, output])
            concat = concat[np.newaxis, :, :, :]
            # print('[CHECK] concat.shape: {}'.format(concat.shape))
            if count_frame == 1:
                video = concat.copy()
            else:
                video = np.concatenate((video, concat), axis=0)
            if args.save_cap_dir != None:
                cv2.imwrite('{}out_{}.png'.format(args.save_cap_dir, count_frame), output)

        else:
            break

        ### Print the elapsed time of processing
        t2 = time.time()
        print('[TIME] elapsed time per frame: {}'.format(t2 - t1))
        print('[TIME] mean time for detecting per frame: {}'.format(total_time_ssd / count_frame))
        print('[TIME] mean time for inpainting per frame: {}'.format(total_time_glcic / count_frame))
        print('[TIME] mean time for whole processing per frame: {}'.format((total_time_ssd + total_time_inpaint) / count_frame))
        count_frame += 1

    ### Processsing after all frames process.
    t3 = time.time()
    print('[TIME] total elapsed time for processing images: {}'.format(t3 - t1))

    ### Stop video process
    cap.release()
    cv2.destroyAllWindows()

    ### Write a new video
    video_name = args.video.split('/')[-1]
    outfile = './data/video/out{}_{}'.format(args.output, video_name)
    fps = args.fps
    codecs = 'H264'
    # ret, frames, height, width, ch = video.shape
    frames, height, width, ch = video.shape

    fourcc = cv2.VideoWriter_fourcc(*codecs)
    writer = cv2.VideoWriter(outfile, fourcc, fps, (width, height))

    for i in range(frames):
        writer.write(video[i])
    writer.release()
    t4 = time.time()
    print('[INFO] elapsed time for saving video: {}'.format(t4 - t3))

